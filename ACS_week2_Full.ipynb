{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNh8z0bsAgBbHnJJc1RPnZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aslestia/ACS_2025/blob/main/ACS_week2_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "collapsed": true,
        "id": "tUHj8SiyowFK",
        "outputId": "c20fdbc6-61c6-4643-9048-f0a970bf182e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value Iteration — Values:\n",
            " 3.2 |  4.4 |  5.7 |  7.1\n",
            " 4.4 |  3.2 |  0.0 |  8.5\n",
            " 5.7 |  0.0 |  8.5 | 10.0\n",
            " 7.1 |  8.5 | 10.0 |  0.0\n",
            "\n",
            "Value Iteration — Policy:\n",
            "→ → → ↓\n",
            "↓ ↑ ■ ↓\n",
            "↓ ■ → ↓\n",
            "→ → → ■\n",
            "\n",
            "Iterasi: 7 | Waktu: 0.0031s\n",
            "Policy Iteration — Values:\n",
            " 3.2 |  4.4 |  5.7 |  7.1\n",
            " 4.4 |  3.2 |  0.0 |  8.5\n",
            " 5.7 |  0.0 |  8.5 | 10.0\n",
            " 7.1 |  8.5 | 10.0 |  0.0\n",
            "\n",
            "Policy Iteration — Policy:\n",
            "→ → → ↓\n",
            "↓ ↑ ■ ↓\n",
            "↓ ■ → ↓\n",
            "→ → → ■\n",
            "\n",
            "Iterasi: 6 | Waktu: 0.1520s\n",
            "== Skenario A (gamma 0.9) ==\n",
            "gamma=0.9, slip=0.0, step=-1.0\n",
            "VI iters: 7 | PI iters: 7\n",
            "== Skenario B (slip 0.1) ==\n",
            "gamma=0.95, slip=0.1, step=-1.0\n",
            "VI iters: 24 | PI iters: 4\n",
            "== Skenario C (trap -5) ==\n",
            "gamma=0.95, slip=0.0, step=-1.0\n",
            "VI iters: 7 | PI iters: 6\n"
          ]
        }
      ],
      "source": [
        "#ACS_week2_Gridworlds_DP2\n",
        "import numpy as np, time, matplotlib.pyplot as plt\n",
        "\n",
        "# Parameter mudah diubah\n",
        "H, W = 4, 4\n",
        "START = (0,0)\n",
        "GOALS = {(3,3): +10}\n",
        "TRAPS = {(1,2):-10, (2,1):-10}\n",
        "STEP_REWARD = -1.0\n",
        "GAMMA = 0.95\n",
        "SLIP = 0.0   # 0.1 untuk transisi probabilistik\n",
        "EPS = 1e-6\n",
        "ACTIONS = {0: (-1,0), 1: (0,1), 2: (1,0), 3: (0,-1)}   # U,R,D,L\n",
        "ARROWS  = {0:\"↑\", 1:\"→\", 2:\"↓\", 3:\"←\", -1:\"■\"}\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self, H, W, start, goals, traps, step_reward, gamma, slip=0.0):\n",
        "        self.H, self.W = H, W\n",
        "        self.start = start\n",
        "        self.goals = goals\n",
        "        self.traps = traps\n",
        "        self.step_reward = step_reward\n",
        "        self.gamma = gamma\n",
        "        self.slip = slip\n",
        "        self.nS, self.nA = H*W, 4\n",
        "\n",
        "    def idx(self, s): return s[0]*self.W + s[1]\n",
        "    def state_from_idx(self, i): return (i//self.W, i%self.W)\n",
        "    def in_bounds(self, r,c): return 0<=r<self.H and 0<=c<self.W\n",
        "    def is_terminal(self, s): return s in self.goals or s in self.traps\n",
        "\n",
        "    def transitions(self, s, a):\n",
        "        if self.is_terminal(s): return [(1.0, s, 0.0)]\n",
        "        dr, dc = ACTIONS[a]\n",
        "        cand = (s[0]+dr, s[1]+dc)\n",
        "        if not self.in_bounds(*cand): cand = s\n",
        "        left, right = (a-1)%4, (a+1)%4\n",
        "        candL = (s[0]+ACTIONS[left][0], s[1]+ACTIONS[left][1])\n",
        "        candR = (s[0]+ACTIONS[right][0], s[1]+ACTIONS[right][1])\n",
        "        candL = candL if self.in_bounds(*candL) else s\n",
        "        candR = candR if self.in_bounds(*candR) else s\n",
        "        p_main = 1.0 - 2*self.slip\n",
        "        outs = [(p_main, cand), (self.slip, candL), (self.slip, candR)]\n",
        "        ts = []\n",
        "        for p, sn in outs:\n",
        "            if p<=0: continue\n",
        "            r = self.goals.get(sn, self.traps.get(sn, self.step_reward))\n",
        "            ts.append((p, sn, r))\n",
        "        return ts\n",
        "\n",
        "def print_values(env, V):\n",
        "    grid = np.zeros((env.H, env.W))\n",
        "    for i in range(env.nS):\n",
        "        r,c = env.state_from_idx(i); grid[r,c] = V[i]\n",
        "    for r in range(env.H):\n",
        "        print(\" | \".join(f\"{grid[r,c]:4.1f}\" for c in range(env.W)))\n",
        "    print()\n",
        "\n",
        "def print_policy(env, Pi):\n",
        "    for r in range(env.H):\n",
        "        row=[]\n",
        "        for c in range(env.W):\n",
        "            s=(r,c)\n",
        "            row.append(ARROWS[-1] if env.is_terminal(s) else ARROWS[Pi[env.idx(s)]])\n",
        "        print(\" \".join(row))\n",
        "    print()\n",
        "\n",
        "def show_grid(env):\n",
        "    fig, ax = plt.subplots(figsize=(4,4))\n",
        "    for x in range(env.W+1): ax.plot([x,x],[0,env.H],color=\"k\",lw=1)\n",
        "    for y in range(env.H+1): ax.plot([0,env.W],[y,y],color=\"k\",lw=1)\n",
        "    for (r,c),val in env.goals.items():\n",
        "        ax.add_patch(plt.Rectangle((c, r),1,1,color=\"green\",alpha=0.25))\n",
        "        ax.text(c+0.5,r+0.5,f\"GOAL\\n{val:+}\",ha=\"center\",va=\"center\")\n",
        "    for (r,c),val in env.traps.items():\n",
        "        ax.add_patch(plt.Rectangle((c, r),1,1,color=\"red\",alpha=0.25))\n",
        "        ax.text(c+0.5,r+0.5,f\"TRAP\\n{val:+}\",ha=\"center\",va=\"center\")\n",
        "    sr,sc = env.start\n",
        "    ax.text(sc+0.5,sr+0.5,\"START\",color=\"blue\",ha=\"center\",va=\"center\")\n",
        "    ax.set_xlim(0,env.W); ax.set_ylim(env.H,0); ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.set_title(\"GridWorld\"); plt.show()\n",
        "\n",
        "# -----------Value Iteration -----------\n",
        "def value_iteration(env, eps=1e-6, max_iter=1000):\n",
        "    V = np.zeros(env.nS)\n",
        "    t0=time.time(); iters=0\n",
        "    for it in range(max_iter):\n",
        "        iters=it+1; delta=0.0; V_new=V.copy()\n",
        "        for i in range(env.nS):\n",
        "            s=env.state_from_idx(i)\n",
        "            if env.is_terminal(s): V_new[i]=0.0; continue\n",
        "            qbest=-1e18\n",
        "            for a in range(4):\n",
        "                q=0.0\n",
        "                for p,sn,r in env.transitions(s,a):\n",
        "                    q += p*(r + env.gamma*V[env.idx(sn)])\n",
        "                qbest=max(qbest,q)\n",
        "            delta=max(delta,abs(qbest-V[i])); V_new[i]=qbest\n",
        "        V=V_new\n",
        "        if delta<eps: break\n",
        "    # greedy policy\n",
        "    Pi=np.full(env.nS,-1,int)\n",
        "    for i in range(env.nS):\n",
        "        s=env.state_from_idx(i)\n",
        "        if env.is_terminal(s): continue\n",
        "        qbest,a_best=-1e18,0\n",
        "        for a in range(4):\n",
        "            q=0.0\n",
        "            for p,sn,r in env.transitions(s,a):\n",
        "                q += p*(r + env.gamma*V[env.idx(sn)])\n",
        "            if q>qbest: qbest,a_best=q,a\n",
        "        Pi[i]=a_best\n",
        "    return V, Pi, iters, time.time()-t0\n",
        "\n",
        "\n",
        "# ----------- Policy Evaluation -----------\n",
        "def policy_evaluation(env, Pi, eps=1e-6, max_iter=1000):\n",
        "    V=np.zeros(env.nS)\n",
        "    for _ in range(max_iter):\n",
        "        delta=0.0\n",
        "        for i in range(env.nS):\n",
        "            s=env.state_from_idx(i)\n",
        "            if env.is_terminal(s): newv=0.0\n",
        "            else:\n",
        "                a=Pi[i]; newv=0.0\n",
        "                for p,sn,r in env.transitions(s,a):\n",
        "                    newv += p*(r + env.gamma*V[env.idx(sn)])\n",
        "            delta=max(delta,abs(newv-V[i])); V[i]=newv\n",
        "        if delta<eps: break\n",
        "    return V\n",
        "\n",
        "def policy_improvement(env, V):\n",
        "    Pi=np.full(env.nS,-1,int); stable=True\n",
        "    for i in range(env.nS):\n",
        "        s=env.state_from_idx(i)\n",
        "        if env.is_terminal(s): continue\n",
        "        best_a,best_q=0,-1e18\n",
        "        for a in range(4):\n",
        "            q=0.0\n",
        "            for p,sn,r in env.transitions(s,a):\n",
        "                q += p*(r + env.gamma*V[env.idx(sn)])\n",
        "            if q>best_q: best_q,best_a=q,a\n",
        "        if Pi[i]!=-1 and Pi[i]!=best_a: stable=False\n",
        "        Pi[i]=best_a\n",
        "    return Pi, stable\n",
        "\n",
        "def policy_iteration(env, eps=1e-6, max_iter=100):\n",
        "    Pi=np.zeros(env.nS,dtype=int)\n",
        "    for i in range(env.nS):\n",
        "        if env.is_terminal(env.state_from_idx(i)): Pi[i]=-1\n",
        "    t0=time.time(); iters=0\n",
        "    for k in range(max_iter):\n",
        "        iters=k+1\n",
        "        V=policy_evaluation(env,Pi,eps=eps)\n",
        "        newPi,_=policy_improvement(env,V)\n",
        "        if np.array_equal(newPi,Pi): return V,Pi,iters,time.time()-t0\n",
        "        Pi=newPi\n",
        "    return V,Pi,iters,time.time()-t0\n",
        "\n",
        "env = GridWorld(H,W,START,GOALS,TRAPS,STEP_REWARD,GAMMA,SLIP)\n",
        "show_grid(env)\n",
        "\n",
        "V_vi, Pi_vi, it_vi, t_vi = value_iteration(env, eps=EPS)\n",
        "print(\"Value Iteration — Values:\"); print_values(env, V_vi)\n",
        "print(\"Value Iteration — Policy:\"); print_policy(env, Pi_vi)\n",
        "print(f\"Iterasi: {it_vi} | Waktu: {t_vi:.4f}s\")\n",
        "\n",
        "V_pi, Pi_pi, it_pi, t_pi = policy_iteration(env, eps=EPS)\n",
        "print(\"Policy Iteration — Values:\"); print_values(env, V_pi)\n",
        "print(\"Policy Iteration — Policy:\"); print_policy(env, Pi_pi)\n",
        "print(f\"Iterasi: {it_pi} | Waktu: {t_pi:.4f}s\")\n",
        "\n",
        "def run_scenario(gamma=0.95, slip=0.0, step=-1.0, goals=None, traps=None, title=\"\"):\n",
        "    env = GridWorld(H,W,START, goals or GOALS, traps or TRAPS, step, gamma, slip)\n",
        "    V_vi, Pi_vi, it_vi, _ = value_iteration(env, eps=EPS)\n",
        "    V_pi, Pi_pi, it_pi, _ = policy_iteration(env, eps=EPS)\n",
        "    print(f\"== {title} ==\")\n",
        "    print(f\"gamma={gamma}, slip={slip}, step={step}\")\n",
        "    print(\"VI iters:\", it_vi, \"| PI iters:\", it_pi)\n",
        "    return (env, V_vi, Pi_vi, V_pi, Pi_pi)\n",
        "\n",
        "# Contoh:\n",
        "_ = run_scenario(gamma=0.9, title=\"Skenario A (gamma 0.9)\")\n",
        "_ = run_scenario(slip=0.1, title=\"Skenario B (slip 0.1)\")\n",
        "_ = run_scenario(traps={(1,2):-5,(2,1):-5}, title=\"Skenario C (trap -5)\")"
      ]
    }
  ]
}