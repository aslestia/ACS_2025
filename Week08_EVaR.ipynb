{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6l1B1soRuMB"
      },
      "source": [
        "# Week 8 Unified Practicum: Pricing (Loss) + CliffWalking (Returns)\n",
        "- **Pricing**: Expected, VaR, CVaR, EVaR on light vs heavy tail losses.\n",
        "- **RL Mini-Project (CliffWalking)**: REINFORCE vs EVaR-PG, metrics = mean return, VaR, CVaR, fall frequency.\n",
        "- α-levels used: **0.95** and **0.99**.\n",
        "- Exports: CSV tables for pricing and RL metrics.\n",
        "\n",
        "> Notes: Matplotlib only, single-plot per figure, default colors."
      ],
      "id": "C6l1B1soRuMB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isgXlQ7PRuMF"
      },
      "source": [
        "## Utilities: Risk Measures"
      ],
      "id": "isgXlQ7PRuMF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8jUKhGtRuMH"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "# VaR & CVaR for arrays x. For returns (higher is better), the lower-tail (worse) is <= VaR.\n",
        "def var_alpha(x, alpha=0.95):\n",
        "    x = np.sort(np.asarray(x))\n",
        "    idx = max(0, min(int(np.floor(alpha*len(x))) - 1, len(x)-1))\n",
        "    return float(x[idx])\n",
        "\n",
        "def cvar_alpha_returns(returns, alpha=0.95):\n",
        "    v = var_alpha(returns, alpha)\n",
        "    tail = np.asarray(returns)[np.asarray(returns) <= v]\n",
        "    if len(tail)==0: return v\n",
        "    return float(tail.mean())\n",
        "\n",
        "def cvar_alpha_losses(losses, alpha=0.95):\n",
        "    v = np.quantile(losses, alpha)\n",
        "    tail = np.asarray(losses)[np.asarray(losses) >= v]\n",
        "    if len(tail)==0: return float(v)\n",
        "    return float(tail.mean())\n",
        "\n",
        "def evar_alpha_losses(losses, alpha=0.95, lambdas=None):\n",
        "    x = np.asarray(losses, dtype=float)\n",
        "    if lambdas is None:\n",
        "        lambdas = np.logspace(-3, 2, 200)\n",
        "    best = np.inf\n",
        "    for lam in lambdas:\n",
        "        y = lam * x\n",
        "        m = np.max(y)\n",
        "        log_mgf = m + np.log(np.mean(np.exp(y - m)))\n",
        "        val = (log_mgf - np.log(1.0 - alpha)) / lam\n",
        "        if val < best: best = val\n",
        "    return float(best)"
      ],
      "id": "Y8jUKhGtRuMH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5X5nApJRuMK"
      },
      "source": [
        "## Part A — Claim Pricing (Loss Domain)"
      ],
      "id": "o5X5nApJRuMK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRLzdPPuRuML"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulate light- vs heavy-tail losses\n",
        "N = 50000\n",
        "mu_lt, sigma_lt = 8.5, 0.5\n",
        "light = rng.lognormal(mu_lt, sigma_lt, size=N)\n",
        "\n",
        "mu_ht, sigma_ht = 8.5, 0.8\n",
        "ln = rng.lognormal(mu_ht, sigma_ht, size=N)\n",
        "xm, shape = 5e4, 1.5\n",
        "u = rng.uniform(size=N)\n",
        "pareto = xm * (1 - u) ** (-1.0/shape)\n",
        "mask = rng.uniform(size=N) < 0.2\n",
        "heavy = np.where(mask, pareto, ln)\n",
        "\n",
        "alphas = [0.95, 0.99]\n",
        "\n",
        "def pricing_table_wide(losses, name, alphas=(0.95, 0.99)):\n",
        "    rec = {\"Dataset\": name, \"Expected\": float(np.mean(losses))}\n",
        "    for a in alphas:\n",
        "        v = float(np.quantile(losses, a))\n",
        "        rec[f\"VaR@{a}\"]  = v\n",
        "        rec[f\"CVaR@{a}\"] = cvar_alpha_losses(losses, a)\n",
        "        rec[f\"EVaR@{a}\"] = evar_alpha_losses(losses, a)\n",
        "    return pd.DataFrame([rec])\n",
        "\n",
        "pricing_df = pd.concat([\n",
        "    pricing_table_wide(light, \"Light-tail\"),\n",
        "    pricing_table_wide(heavy, \"Heavy-tail\")\n",
        "], ignore_index=True)\n",
        "pricing_df\n"
      ],
      "id": "kRLzdPPuRuML"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQHfXWWcRuMM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visuals: histogram with VaR/CVaR/EVaR for alpha=0.95 (single plot per dataset)\n",
        "a = 0.95\n",
        "for losses, title in [(light, \"Light-tail\"), (heavy, \"Heavy-tail\")]:\n",
        "    plt.figure()\n",
        "    plt.hist(losses, bins=100)\n",
        "    v = np.quantile(losses, a)\n",
        "    c = cvar_alpha_losses(losses, a)\n",
        "    e = evar_alpha_losses(losses, a)      # <— tambahkan perhitungan EVaR\n",
        "\n",
        "    plt.axvline(v, linestyle='--', linewidth=2, label=f\"VaR@{a}\")\n",
        "    plt.axvline(c, linestyle=':',  linewidth=2, label=f\"CVaR@{a}\")\n",
        "    plt.axvline(e, linestyle='-.', linewidth=2, label=f\"EVaR@{a}\")  # <— gambar EVaR\n",
        "\n",
        "    plt.xlim(0, max(v, c, e) * 1.05)\n",
        "\n",
        "    plt.title(f\"{title} — Histogram Loss with VaR/CVaR/EVaR\")\n",
        "    plt.xlabel(\"Loss\"); plt.ylabel(\"Frequency\"); plt.legend()\n",
        "    plt.show()\n"
      ],
      "id": "KQHfXWWcRuMM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vWfDCnRuMN"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Show pricing table nicely (no CSV)\n",
        "from IPython.display import display\n",
        "\n",
        "# Define a dictionary to specify formatting for numeric columns\n",
        "numeric_cols = pricing_df.select_dtypes(include=np.number).columns.tolist()\n",
        "format_dict = {col: \"{:,.0f}\" for col in numeric_cols}\n",
        "\n",
        "display(\n",
        "    pricing_df\n",
        "      .copy()\n",
        "      .sort_values([\"Dataset\"])  # sesuaikan bila ada kolom 'alpha'\n",
        "      .style.format(format_dict, na_rep=\"–\")  # ribuan, tanpa desimal\n",
        "           #.hide_index() # Removed unsupported method\n",
        ")\n",
        "\n",
        "# from IPython.display import display # Commented out undefined DataFrame usage\n",
        "\n",
        "# wide = (pricing_df_long # Commented out undefined DataFrame usage\n",
        "#         .pivot_table(index=\"Dataset\", columns=\"alpha\", # Commented out undefined DataFrame usage\n",
        "#                      values=[\"VaR\",\"CVaR\",\"EVaR\"], aggfunc=\"first\")) # Commented out undefined DataFrame usage\n",
        "# # urut kolom agar rapi # Commented out undefined DataFrame usage\n",
        "# wide = wide.reindex(sorted(wide.columns, key=lambda x: (x[0], x[1])), axis=1) # Commented out undefined DataFrame usage\n",
        "\n",
        "# display(wide.style.format(\"{:,.0f}\", na_rep=\"–\")) # Commented out undefined DataFrame usage"
      ],
      "id": "48vWfDCnRuMN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ANbtvBRuMO"
      },
      "source": [
        "## Part B — RL Mini-Project: CliffWalking (Return Domain)"
      ],
      "id": "I_ANbtvBRuMO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_q5Hf0tRuMP"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "class CliffWalking:\n",
        "    def __init__(self, H=4, W=12):\n",
        "        self.H, self.W = H, W\n",
        "        self.start = (H-1, 0); self.goal = (H-1, W-1)\n",
        "        self.cliff = {(H-1, j) for j in range(1, W-1)}\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.s = self.start\n",
        "        return self.s\n",
        "    def step(self, a):\n",
        "        i,j = self.s\n",
        "        di = [-1,0,1,0][a]; dj = [0,1,0,-1][a]\n",
        "        ni = max(0, min(self.H-1, i+di)); nj = max(0, min(self.W-1, j+dj))\n",
        "        ns = (ni, nj); r = -1.0; done = False; fell = False\n",
        "        if ns in self.cliff:\n",
        "            r = -100.0; fell = True; ns = self.start    # continue episode\n",
        "        elif ns == self.goal:\n",
        "            done = True\n",
        "        self.s = ns\n",
        "        return ns, r, done, {\"fell\": fell}\n",
        "\n",
        "\n",
        "env = CliffWalking(); nS=env.H*env.W; nA=4\n",
        "\n",
        "def s2i(s): return s[0]*env.W + s[1]\n",
        "def softmax(z):\n",
        "    z = z - np.max(z); ez = np.exp(z); return ez/np.sum(ez)\n",
        "\n",
        "theta0 = np.zeros((nS,nA))\n",
        "\n",
        "def sample_episode(theta, max_steps=500):\n",
        "    s = env.reset(); traj=[]\n",
        "    for t in range(max_steps):\n",
        "        p = softmax(theta[s2i(s)]); a = np.random.choice(nA, p=p)\n",
        "        ns, r, done, info = env.step(a)\n",
        "        traj.append((s,a,r,info[\"fell\"]))\n",
        "        s = ns\n",
        "        if done: break\n",
        "    return traj\n",
        "\n",
        "def returns(traj, gamma=1.0):\n",
        "    G=0.0; out=[]\n",
        "    for s,a,r,f in reversed(traj):\n",
        "        G = r + gamma*G; out.append(G)\n",
        "    return list(reversed(out))"
      ],
      "id": "s_q5Hf0tRuMP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IFEqUA_RuMQ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train: REINFORCE vs EVaR-PG (fixed λ). Evaluate for α=0.95 and α=0.99\n",
        "alpha_list = [0.95, 0.99]\n",
        "lam = 0.05\n",
        "lr = 0.05\n",
        "\n",
        "def train(method=\"risk_neutral\", episodes=1500, lr=0.01, lam=0.01):\n",
        "    th = np.zeros_like(theta0); rets = []\n",
        "    for ep in range(episodes):\n",
        "        traj = sample_episode(th)\n",
        "        Gs = returns(traj)\n",
        "        rets.append(sum(r for *_, r, _ in traj))\n",
        "        b = np.mean(Gs)  # baseline\n",
        "        for t,(s,a,r,f) in enumerate(traj):\n",
        "            G = Gs[t]; p = softmax(th[s2i(s)])\n",
        "            one = np.zeros(nA); one[a] = 1\n",
        "            if method == \"risk_neutral\":\n",
        "                w = (G - b)\n",
        "            else:  # EVaR-PG (λ fixed, stabilised)\n",
        "                w = -np.exp(-lam*G) + np.exp(-lam*b)\n",
        "            th[s2i(s)] += lr * (one - p) * w\n",
        "    return th, np.array(rets)\n",
        "\n",
        "\n",
        "th_rn, mets_rn = train(\"risk_neutral\")\n",
        "th_ev, mets_ev = train(\"evar\")\n",
        "\n",
        "plt.figure(); plt.plot(mets_rn, label=\"REINFORCE\"); plt.plot(mets_ev, label=\"EVaR-PG (λ fixed)\")\n",
        "plt.title(\"Episode Returns during Training (CliffWalking)\"); plt.xlabel(\"Episode\"); plt.ylabel(\"Return\"); plt.legend(); plt.show()\n",
        "\n",
        "def evaluate(theta, nroll=3000, alpha=0.95):\n",
        "    rets=[]; falls=0\n",
        "    for _ in range(nroll):\n",
        "        tr = sample_episode(theta)\n",
        "        rets.append(sum(r for *_, r, _ in tr))\n",
        "        if any(f for *_, f in tr): falls+=1\n",
        "    rets = np.array(rets)\n",
        "    return {\n",
        "        \"mean_return\": float(np.mean(rets)),\n",
        "        f\"VaR@{alpha}\": var_alpha(rets, alpha),\n",
        "        f\"CVaR@{alpha}\": cvar_alpha_returns(rets, alpha),\n",
        "        \"fall_freq\": falls/nroll\n",
        "    }\n",
        "\n",
        "# Build evaluation table for both alphas\n",
        "rows = []\n",
        "for a in alpha_list:\n",
        "    ev_rn = evaluate(th_rn, alpha=a)\n",
        "    ev_ev = evaluate(th_ev, alpha=a)\n",
        "    rows.append({\"Policy\":\"Risk-neutral\", **ev_rn, \"alpha\": a})\n",
        "    rows.append({\"Policy\":\"EVaR-PG\", **ev_ev, \"alpha\": a})\n",
        "\n",
        "rl_metrics_df = pd.DataFrame(rows)\n",
        "rl_metrics_df"
      ],
      "id": "4IFEqUA_RuMQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmL1eWcYRuMR"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Show RL metrics nicely in the notebook\n",
        "from IPython.display import display\n",
        "\n",
        "# (opsional) urut & pembulatan agar rapi\n",
        "view_cols = [c for c in rl_metrics_df.columns]  # atau pilih kolom spesifik\n",
        "out_df = (rl_metrics_df\n",
        "          .sort_values([\"Policy\",\"alpha\"])\n",
        "          .copy())\n",
        "\n",
        "display(out_df.style.format(precision=3))\n",
        "\n",
        "# Bar chart per-metrik: mean_return, VaR, CVaR, fall_rate (sesuaikan nama kolom Anda)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "num_cols = [c for c in rl_metrics_df.columns\n",
        "            if c not in [\"Policy\",\"alpha\"] and pd.api.types.is_numeric_dtype(rl_metrics_df[c])]\n",
        "\n",
        "# Sumbu-x: kombinasi agent–alpha\n",
        "x_labels = rl_metrics_df[[\"Policy\",\"alpha\"]].astype(str).agg(\" | \".join, axis=1)\n",
        "\n",
        "for metric in num_cols:\n",
        "    plt.figure()\n",
        "    plt.title(f\"{metric} per policy (agent | alpha)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.bar(x_labels, rl_metrics_df[metric])   # 1 plot/figur, tidak set warna\n",
        "    plt.ylabel(metric)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "wmL1eWcYRuMR"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}